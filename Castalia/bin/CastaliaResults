#!/usr/bin/python
import os, sys, commands, getopt, re, math
from optparse import OptionParser

z_values = {99:2.577,98.5:2.43,97.5:2.243,95:1.96,90:1.645,85:1.439,75:1.151}

parser = OptionParser(usage="usage: %prog -i FILE [options]")
parser.add_option("-i","--input", dest="input", type="string", metavar="FILE", help="Load results from FILE")
parser.add_option("-f","--filter", dest="filter", type="string", metavar="RE", help="Select a subset of available outputs by applying RE (regular expression) filter")
parser.add_option("-o","--output", dest="output", type="int", default=1, metavar="[1|2]", help="Choose output type, supported values are 1 (visual) and 2 (compact)")
parser.add_option("-n","--node", dest="pernode", default=False, action="store_true", help="Display results for each node individually")
parser.add_option("-c","--confidence", dest="confidence", type="float", metavar="CL", help="Select desired confidence level (CL) and display confidence intervals where possible, supported values of CL: " + str(sorted(z_values.keys())))
parser.add_option("-p","--percentage", dest="percentage", default=False, action="store_true", help="Display breakdowns as percentage of total amounts where possible")
parser.add_option("-r","--row", dest="row_filter", type="string", metavar="RE", help="Select a subset of rows by applying RE (regular expression) filter")
(options,args) = parser.parse_args()

if options.confidence and options.confidence not in z_values:
	quit("ERROR: supported values of confidence level are " + str(sorted(z_values.keys())))
if not options.input:
	quit("ERROR: -i option is mandatory, input file required")

# reworked from http://code.activestate.com/recipes/135435-sort-a-string-using-numeric-order/
def sorted_copy(alist):
	indices = map(_generate_index, alist)
	decorated = zip(indices, alist)
	decorated.sort()
	return [ item for index, item in decorated ]

def _generate_index(str):
	# Splits a string into alpha and numeric elements, which
	# is used as an index for sorting
	index = []
	
	def _append(fragment, alist=index):
		if fragment.isdigit(): 
			fragment = int(fragment)
			if len(alist) > 0 and alist[-1][-1] == "-": 
				fragment = -fragment
				alist[-1] = alist[-1][:-1]
		alist.append(fragment)
	
	# initialize loop
	if len(str) > 0: prev_isdigit = str[0].isdigit()
	current_fragment = ''
	# group a string into digit and non-digit parts
	for char in str:
		curr_isdigit = char.isdigit()
		if curr_isdigit == prev_isdigit:
			current_fragment += char
		else:
			_append(current_fragment)
			current_fragment = char
			prev_isdigit = curr_isdigit
	_append(current_fragment)
	return tuple(index)

# simple function to determine if a number has floating point component
def is_int(num):
	if type(num) != float: return False
	return num*10%10 == 0

# a class to store information from a single simple output
class Output():
	def __init__(self, name,n,i):
		self.name = name
		self.data = {}
		self.min_i = self.max_i = int(i)
		self.min_n = self.max_n = int(n)
		self.num = 0
		self.nxi = {}
		self.nxi_max = {}
		self.nxi_total = {}

	def add(self,n,i,bl,l,v):
		i = int(i)
		n = int(n)
		if self.min_i > i:
			self.min_i = i
		elif self.max_i < i:
			self.max_i = i
		if self.min_n > n:
			self.min_n = n
		elif self.max_n < n:
			self.max_n = n
		self.i = self.max_i - self.min_i + 1
		self.n = self.max_n - self.min_n + 1
		
		if l not in self.data:
			self.data[l] = {}
		data = self.data[l]
		
		if bl not in data:
			data[bl] = {}
		data = data[bl]
		
		key = str(n) + ":" + str(i)
		key2 = key + ":" + l

		if bl not in self.nxi:
			self.nxi[bl] = {}
		if key2 not in self.nxi[bl]:
			self.nxi[bl][key2] = 0
		self.nxi[bl][key2] += 1
		if bl not in self.nxi_max or self.nxi[bl][key2] > self.nxi_max[bl]:
			self.nxi_max[bl] = self.nxi[bl][key2]
		if bl not in self.nxi_total:
			self.nxi_total[bl] = {}
		self.nxi_total[bl][key] = 1
		
		if key not in data:
			data[key] = []
		data[key].append(v)
	
	def pernode_total(self,bl):
		return self.nxi_max[bl]
	
	def total(self,bl):
		return self.nxi_max[bl]*len(self.nxi_total[bl].keys())
		
modules = {}

# this function will look for a module with a given name 'm' in dictionary 'modules'
# if module is not present, a new entry will be added. Next an output 'o' is 
# located in the module (again, new entry is created if not found)
# finally, add() function is called to save a particular output value
def saveOutput(m,n,i,o,bl,l,v):
	if m not in modules: modules[m] = {}
	m = modules[m]
	if o not in m: m[o] = Output(o,n,i)
	m[o].add(n,i,bl,l,v)

# find mean and confidence interval of a list of values
def mean_ci(list,amt=None):
	#calculate mean
	mean = 0
	for n in list: mean += float(n)
	if (amt == None): amt = len(list)
	mean = mean/amt
	
	#check if need to calculate confidence interval
	global options
	if not options.confidence or amt < 2: 
		if is_int(mean):
			return int(mean), None
		else:
			return round(mean,3), None

	#calculate confidence interval
	mean_sq = 0
	for n in list: 
		diff = mean-float(n)
		mean_sq += diff*diff
	std = math.sqrt(mean_sq/amt)/math.sqrt(amt - 1)
	ci = z_values[options.confidence]*std/math.sqrt(amt)
	if is_int(mean):
		return int(mean), round(ci,3)
	else:
		return round(mean,3), round(ci,3)

# this function will print a list of all modules that were added to the 'modules' 
# dictionary. For each module a list of outputs is displayed, and for each output - it's dimensions
def printModules():
	print ""
	data = { "Module":{}, "Output":{}, "Dimensions":{} }
	row = 0
	for mname in sorted(modules.keys()):
		m = modules[mname]
		first = 1
		for oname in sorted(m.keys()):
			row += 1
			if (first):
				data["Module"][row] = mname
				first = 0
			o = m[oname]
			data["Output"][row] = oname
			data["Dimensions"][row] = str(o.n) + "x" + str(o.i)
			if len(o.data.keys()) > 1:
				data["Dimensions"][row] += "(" + str(len(o.data.keys())) + ")"
	printTable(data,"",["Module","Output"])
	print "NOTE: select from the avaliable outputs using -f option\n"

# Displays a table using a specific output format
# 1st argument - dictionary of columns in the table, using column header as key
#		each entry is another dictionary of rows in that column, 
#		using row number as key
# 2nd argument - Optional replacement string for missing cells, default "0"
# 3rd argument - Optional order of columns in the table, columns which are not in
#		order are sorted alphabetically
def printTable(data,missing="0",orderIn=[]):
	global options
	
	# row filter may force us to skip some rows
	regexp = None
	if (options.row_filter): regexp = re.compile(options.row_filter, re.I)
	
	# initialise order of columns
	order = []
	
	# first, copy all column names from prefidened orderIn
	for colname in orderIn: order.append(colname)
	
	# next, append all missing columns in alphabetical order
	for colname in sorted_copy(data.keys()):
		if colname not in order: order.append(colname)
		
	# calculate width of each column by looping through corresponding dictionary
	# also use the same loop to determine the total number of rows in the table
	widths = {}
	rows = 0;
	for colname in order:
		# initialise width for each column with the width of its header
		if colname not in widths: widths[colname] = len(colname)
		
		# inspect width of each sell and record maximum
		# also record the highest row seen (for total number of rows)
		col = data[colname]
		for row in col.keys():
			if int(row) > rows: rows = int(row)
			cell = col[row]
			if len(str(cell)) > widths[colname]:
				widths[colname] = len(str(cell))

	# visual output
	if options.output == 1:
		line = ""		# this is separating line, printed on top, bottom and 
						# to separate headers and table data
		header = ""		# this string holds formatted table headers, formatted
						# according to column widths
						
		# initialise 'header' and 'line' variables
		for colname in order:
			if colname in orderIn: header += "| " + colname.rjust(widths[colname]) + " "
			else: header += "| " + colname.ljust(widths[colname]) + " "
			line += "+" + "-"*(widths[colname]+2)
		header += "|"
		line += "+"
		
		# loop through all rows of the table
		first_row = 1
		for row in range(1,rows+1):
			# check if we have row filter. If yes, it has to match for row to be displayed
			if regexp == None or "" not in data or regexp.search(data[""][row]):
				
				# if this is first row, print table header
				if first_row:
					print line
					print header
					print line
					first_row = 0
				
				# print all cells of this row by looping through columns
				for colname in order:
					if row in data[colname]: cell = str(data[colname][row])
					else: cell = missing
					if colname in orderIn: print "|", cell.rjust(widths[colname]),
					else: print "|", cell.ljust(widths[colname]),
				print "|"
		
		# print the final horisontal line
		if first_row: print "[Table is empty]"
		else: print line
		
	# compact output
	elif options.output == 2:
		first_row = 1
		# loop through all rows of the table
		for row in range(1,rows+1):
			# check if we have row filter. If yes, it has to match for row to be displayed
			if regexp == None or "" not in data or row not in data[""] or regexp.search(data[""][row]):
				
				# if this is first row, print table header
				if first_row: 
					print " | ".join(order)
					first_row = 0
				
				# print all cells of this row by looping through columns
				row_data = []
				for colname in order:
					if row in data[colname]: row_data.append(str(data[colname][row]))
					else: row_data.append(missing)
				print " | ".join(row_data)

# this function will analyze the output and print it depending on its contents
# 1st argument - name of the output to be printed
# 2nd argument - output object to be printed
def printOutput(name,o):
	global options

	# start by printing the name
	print "\n", name
	
	# initialise the table structure, initially the table holds 1 empty column
	# with row headers. This column might be deleted later if no headers will be
	# found
	table = {"":{}}
	if options.confidence: table_ci = {"":{}}
	else: table_ci = None
	
	# print_i and print_n variables indicate wether index and node information
	# is worth displaying (i.e. theres more than one index and more than one node)
	print_i = 1
	print_n = 1
	if o.min_i == o.max_i: print_i = 0
	if o.min_n == o.max_n: print_n = 0
	
	# first breaking point of the function is to check the number of labels in the
	# output. If multiple labels present then they will be used as column headers
	if len(o.data.keys()) > 1:
		# 'have_header' variable will indicate if rows in the table will have headers
		have_header = 0
		# 'tmp_table' variable is used to temporarily store table data as it is
		# being structured
		tmp_table = {}
		tmp_table_headers = {}
		
		# loop through available labels in this output
		for l in sorted_copy(o.data.keys()):
			# add the label to the resulting table
			if l not in table: table[l] = {}
			
			# extract the data for a particular label
			data = o.data[l]
			# if data has more than one entry, we will need row headers
			if len(data.keys()) > 1: have_header = 1
			
			# if table needs to be displayed on a per node basis,
			# we will use a separate row for each node
			if (options.pernode):
				# check each entry for that label, in alphabetical order
				for bl in sorted_copy(data.keys()):
					# if we have sufficient node or index data, we are also 
					# bound to display them as headers 'have_header' may 
					# already be 1 at this point
					if print_i or print_n: have_header = 1
					
					# go though each combination of node:index, 
					# avaliable for this output
					for n in range(o.min_n,o.max_n+1):
						for i in range(o.min_i,o.max_i+1):
							key = str(n)+":"+str(i)
							if key in data[bl]:
								# create a header for this row
								bl_ni = bl
								if print_n: bl_ni += ",node="+str(n)
								if print_i: bl_ni += ",index="+str(i)
								
								# if this row already exists in tmp_table, append 
								# otherwise create an entry in tmp_table
								if bl_ni in tmp_table:
									if l in tmp_table[bl_ni]: tmp_table[bl_ni][l].extend(data[bl][key])
									else: tmp_table[bl_ni][l] = data[bl][key]
								else: 
									tmp_table[bl_ni] = {l:data[bl][key]}
									tmp_table_headers[bl_ni] = bl
								# rest of the work will be done later, when we 
								# finished top level loop (i.e. converting tmp_table
								# to normal table
			
			# we will group all nodes together to become a single row
			else:
				row = 0
				#check each entry for the label, in alphabetical order
				for bl in sorted_copy(data.keys()):
					# count the current row
					if bl in tmp_table_headers:
						current_row = tmp_table_headers[bl]
					else:
						row = len(tmp_table_headers.keys()) + 1
						tmp_table_headers[bl] = current_row = row
					
					# here tmp_table is simply a list of all recorded values
					tmp_table = []
					
					# add a row header
					table[""][current_row] = bl
					
					# aggregate data across all nodes and indexes
					for n in range(o.min_n,o.max_n+1):
						for i in range(o.min_i,o.max_i+1):
							key = str(n)+":"+str(i)
							if key in data[bl]: tmp_table.extend(data[bl][key])
					
					# if atleast one entry exists, record it into the final table
					if len(tmp_table) > 0:
						mean,ci = mean_ci(tmp_table,o.total(bl))
						table[l][current_row] = str(mean)
						# record confidence intervals into a separate table
						if ci and options.confidence:
							table_ci[""][current_row] = bl
							if l not in table_ci: table_ci[l] = {}
							table_ci[l][current_row] = str(ci)
		
		# here we complete the task of converting tmp_table from 'pernode=true' case
		# to the resulting table to be printed
		if (options.pernode):
			row = 0
			for bl in sorted_copy(tmp_table.keys()):
				# count the current row
				row += 1
				
				# add a row header
				table[""][row] = bl
				
				# aggregate data from tmp_table
				for l in tmp_table[bl].keys():
					mean,ci = mean_ci(tmp_table[bl][l],o.pernode_total(tmp_table_headers[bl]))
					table[l][row] = str(mean)
					# record confidence intervals into a separate table
					if ci and options.confidence: 
						table_ci[""][row] = bl
						if l not in table_ci: table_ci[l] = {}
						table_ci[l][row] = str(ci)
		
		# if no header is needed, delete that column
		if have_header == 0: del table[""]
		
		# convert absolute values to percentage (if -p option is set)
		if options.percentage:
			# first, calculate the sum of each row
			sum = {}
			for i in range (1,len(tmp_table_headers)+1):
				for l in table.keys():
					if l == "": continue
					if i in table[l]: 
						if i in sum: sum[i] += float(table[l][i])
						else: sum[i] = float(table[l][i])
			
			# divide each cell by the sum of the whole row
			for i in range (1,len(tmp_table_headers)+1):
				for l in table.keys():
					if l == "": continue
					if i in table[l]: 
						table[l][i] = str(round(float(table[l][i])/sum[i],3))
						if options.confidence and len(table_ci.keys()) > 1:
							table_ci[l][i] = str(round(float(table_ci[l][i])/sum[i],6))
		
		# print the resulting table(s)
		printTable(table)
		if options.confidence and len(table_ci.keys()) > 1:
			print name + " - confidence intervals"
			printTable(table_ci)
		return
	
	# this happens when there is only one label in the output, 
	# That is single output value, for example energy spent. 
	l = o.data.keys()[0]
	data = o.data[l]
	
	row = 0			# current row
	bl_rows = {}	# a dictionary with row label as key and row index as value
					# such dictionary is useful since our top level label will be 
					# split, parts of the label will become row headers and other
					# parts will be column headers
	
	# per node option is present, will not aggregate the data here
	if options.pernode:
		# Determine which dimension (node or index) has more values to become primary
		# By default, node dimension is primary, but if index has more values
		# index will become primary. Primary dimension will determine columns
		# of the table
		primary_i = 0
		if (o.max_i - o.min_i > o.max_n - o.min_n): primary_i = 1
		
		# go through each tuple (label,node,index) in the output
		for bl in sorted_copy(data.keys()):
			for n in range(o.min_n,o.max_n+1):
				for i in range(o.min_i,o.max_i+1):
					# key is used to retrieve data from the output
					key = str(n)+":"+str(i)
					if key not in data[bl]: continue
					
					# append node and index information to row and column headers
					# depending on which dimension is primary
					l2 = bl
					if primary_i:
						if print_n: l2 = bl + ",node="+str(n)
						l = "Index="+str(i)
					else:
						if print_i: l2 = bl + ",index="+str(i)
						l = "Node="+str(n)
					
					# determine the index of the row using bl_rows dictionary
					if l2 in bl_rows.keys():
						row_current = bl_rows[l2]
					else:
						row += 1
						bl_rows[l2] = row_current = row
					
					# add row header (if needed)
					if row_current not in table[""]: table[""][row_current] = l2
					# add column header (if needed)
					if l not in table: table[l] = {}
					
					# calculate average and confidence interval for the cell
					mean,ci = mean_ci(data[bl][key],o.pernode_total(bl))
					table[l][row_current] = str(mean)
					
					#if confidence interval is present, record it to a separate table
					if ci and options.confidence: 
						table_ci[""][row_current] = l2
						if l not in table_ci: table_ci[l] = {}
						table_ci[l][row_current] = str(ci)
							
	# no per node option is set, will aggregate all information to a single cell
	else:
		# go through each label in the output
		for bl in sorted(data.keys()):
			# split the label by the first semicolon
			# first part will be the column header and second part will be the row header
			l,l2 = bl.split(",",1)
			
			#determine the index of the row using bl_rows dictionary
			if l2 in bl_rows.keys(): 
				row_current = bl_rows[l2]
			else:
				row += 1
				bl_rows[l2] = row_current = row
				
			# add row header (if needed)
			if row_current not in table[""]: table[""][row_current] = l2
			# add column header (if needed)
			if l not in table: table[l] = {}
			
			# aggregate node and index information into tmp_table
			tmp_table = []
			for n in range(o.min_n,o.max_n+1):
				for i in range(o.min_i,o.max_i+1):
					key = str(n)+":"+str(i)
					if key in data[bl]: tmp_table.extend(data[bl][key])
					
			# calculate average and confidence interval for the aggregated tmp_table
			if len(tmp_table) > 0:
				mean,ci = mean_ci(tmp_table,o.total(bl))
				table[l][row_current] = str(mean)
				
				#if confidence interval is present, record it to a separate table
				if ci and options.confidence: 
					table_ci[""][row_current] = l2
					if l not in table_ci: table_ci[l] = {}
					table_ci[l][row_current] = str(ci)
	printTable(table)
	if options.confidence and len(table_ci.keys()) > 1:
		print name + " - confidence intervals"
		printTable(table_ci)

# calls printOutput function on outputs that match
# specified RE pattern
def printOutputs(pattern):
	regexp = re.compile(pattern, re.I)
	for mname in sorted(modules.keys()):
		m = modules[mname]
		for oname in sorted(m.keys()):
			if (regexp.search(oname)):
				printOutput(mname+":"+oname,m[oname])


# __main__

# open and read the input file
if not os.path.exists(options.input) or not os.path.isfile(options.input):
	quit("ERROR: Unable find input file " + options.input)
f = open(options.input,"r")
lines = f.readlines()
f.close()

# parse the input 
bl = ""
for line in lines:
	# check the 'Castalia|' prefix
	m = re.match(r"^Castalia\|\s+(.+)$",line)
	if (m): line = m.group(1)
	else: continue

	# check for label declaration
	m = re.match(r"^label:(.+)$",line)
	if (m):
		bl = m.group(1)
		continue

	# check for module declaration
	m = re.match(r"^module:SN\.(.+)$",line)
	if (m):
		line = m.group(1)
		i = -1
		# within module declaration look for node information
		m = re.match(r"^node\[(\d+)\]\.(.+)$",line)
		if (m):
			n = m.group(1)
			module = m.group(2)
		else:
			module = line
			n = -1
		continue

	# check for simple output declaration
	m = re.match(r"^simple output name:(.+)$",line)
	if (m):
		o = m.group(1)
		continue

	# check for simple output declaration with an index
	m = re.match(r"^index:(\d+) simple output name:(.+)$",line)
	if (m):
		i = m.group(1)
		o = m.group(2)
		continue

	# check for output data
	m = re.match(r"^([-+]?[0-9]*\.?[0-9]+)\s*(.*)$",line);
	if (m):
		saveOutput(module,n,i,o,bl,m.group(2),m.group(1))
		continue
	
	# check for histogram declaration
	m = re.match(r"^histogram name:(.+)$", line)
	if (m):
		o = m.group(1)
		continue
	
	# check for histogram parameters
	m = re.match(r"histogram_min:([-+]?[0-9]*\.?[0-9]+) histogram_max:([-+]?[0-9]*\.?[0-9]+)$",line)
	if (m):
		histogram_min = float(m.group(1))
		histogram_max = float(m.group(2))
		continue
	
	# check for histogram values, calculate histogram properties and save values
	m = re.match(r"histogram_values\s(.+)$",line)
	if (m):
		vals = m.group(1).split(" ")
		size = len(vals) - 1
		step = float(histogram_max - histogram_min)/size
		if is_int(step): step = int(step)
		curr = histogram_min
		if is_int(curr): curr = int(curr)
		for val in vals:
			next = curr+step
			if is_int(next): next = int(next)
			if next > histogram_max: next = "inf"
			saveOutput(module,n,i,o,bl,"["+str(curr)+","+str(next)+")",val)
			curr += step
			if is_int(curr): curr = int(curr)
		continue

	print "Unknown line in the output: ", line

# if filter is specified, print outputs
# otherwise print the list of avaliable outputs to choose from
if (options.filter): printOutputs(options.filter)
else: printModules()
